{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPQ-V5gypUhp"
      },
      "source": [
        "## Importing packages and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "EcJ5uOstpUhs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import copy\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPVnIjnFvk6X"
      },
      "source": [
        "## Preprocessing the data\n",
        "### removing unused features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "AhsvRFo0pUhu"
      },
      "outputs": [],
      "source": [
        "# Use pandas to loadinto a DataFrame\n",
        "# Y1.csv doesn’t have a header so\n",
        "# add one when loading the file\n",
        "X1 = pd.read_csv(\"data/X1.csv\")\n",
        "Y1 = pd.read_csv(\"data/Y1.csv\", header=None, names=['revenue'])\n",
        "\n",
        "X = X1.drop(['Unnamed: 0', 'img_url', 'description', 'is_adult'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl3yWOPPpUhw"
      },
      "source": [
        "### Preprocessing functions for each used feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TNdqOum4pUhw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Creating empty DataFrame to start\n",
        "\"\"\"\n",
        "n_samples = X.shape[0]\n",
        "data = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Ce4OZO08pUhw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Keeping the directly usable features\n",
        "\"\"\"\n",
        "def get_directrly_usable_features(df):\n",
        "    directly_usable_features = [\"ratings\", \"n_votes\"]\n",
        "    for feature in directly_usable_features:\n",
        "        df[feature] = X[feature]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "0YGTbsy5pUhw",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"production_year\" feature\n",
        "\"\"\"\n",
        "\n",
        "def get_prod_year_feature(df, params):\n",
        "    \n",
        "    style = params[\"production_year_style\"] # \"per_quantile\" / \"per_period_length\" / \"no_period\"\n",
        "    if style != \"no_period\" :\n",
        "        n_year_period = params[\"n_year_period\"]\n",
        "\n",
        "    # Removing previously computed categorie(s) for the \"production_year\" initial feature\n",
        "\n",
        "    for feature in df.columns:\n",
        "        if len(feature) >= 8 and (feature[:6] == \"period\" or feature == \"production_year\"):\n",
        "            df.drop(feature, axis=1, inplace=True)\n",
        "\n",
        "    # Creating new categorie(s) for the \"production_year\" initial feature\n",
        "\n",
        "    prod_year = X[\"production_year\"].copy()\n",
        "    if style == \"per_quantile\" or style == \"per_period_length\":\n",
        "        categories = np.ones((n_year_period, n_samples))\n",
        "\n",
        "        if style == \"per_quantile\":\n",
        "            thresholds = prod_year.quantile(np.arange(1, n_year_period) / n_year_period)\n",
        "        else :\n",
        "            thresholds = np.min(prod_year) + (np.max(prod_year) - np.min(prod_year))*np.arange(1, n_year_period)/n_year_period\n",
        "        for i, threshold in enumerate(thresholds):\n",
        "            categories[i+1] = (prod_year >= threshold).astype(int)\n",
        "            categories[i] -= categories[i+1]\n",
        "        for period in range(n_year_period):\n",
        "            df[\"period {}\".format(period)] = categories[period]\n",
        "    elif style == \"no_period\":\n",
        "        df[\"production_year\"] = prod_year\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "izRYAX6LpUhx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"runtime\" feature\n",
        "\n",
        "The problem is here that we have some missing values, we have to deal with it.\n",
        "\"\"\"\n",
        "\n",
        "def get_runtime_feature(df, params):\n",
        "\n",
        "    # Add other smarter ways ?\n",
        "    \n",
        "    replace_type = params[\"runtime_replace_type\"] # \"zero\" / \"mean\" / \"median\"\n",
        "    \n",
        "    runtime = X[\"runtime\"].copy()\n",
        "    if replace_type == \"zero\":\n",
        "        runtime[runtime == \"\\\\N\"] = 0\n",
        "    if replace_type == \"mean\":\n",
        "        mean = np.mean(runtime[runtime != \"\\\\N\"].astype(float))\n",
        "        runtime[runtime == \"\\\\N\"] = mean\n",
        "    if replace_type == \"median\":\n",
        "        median = np.median(runtime[runtime != \"\\\\N\"].astype(float))\n",
        "        runtime[runtime == \"\\\\N\"] = median\n",
        "    df[\"runtime\"] = runtime.astype(float)    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "8xuppfx9pUhy"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"studio\" feature\n",
        "\"\"\"\n",
        "\n",
        "def get_studio_feature(df, params):\n",
        "    use_PCA = params[\"studio_use_PCA\"]\n",
        "    if use_PCA :\n",
        "        dim = params[\"studio_PCA_dim\"]\n",
        "\n",
        "    # Removing previously computed categorie(s) for the \"studio\" initial feature\n",
        "    for feature in df.columns:\n",
        "        if len(feature) >= 10 and feature[:10] == \"studio_PC_\":\n",
        "            df.drop(feature, axis=1, inplace=True)\n",
        "\n",
        "    # Creating new categorie(s) for the \"studio\" initial feature\n",
        "    studio = copy.deepcopy(X[\"studio\"])\n",
        "    studio_labels = np.unique(studio)\n",
        "    studio_features = np.zeros((len(studio_labels), n_samples))\n",
        "    for i, label in enumerate(studio_labels) :\n",
        "        studio_features[i] = (studio == label).astype(int)\n",
        "    \n",
        "    # Applying pca or not\n",
        "    if use_PCA :\n",
        "        pca = PCA(n_components=dim)\n",
        "        out = pca.fit_transform(studio_features.T)\n",
        "    else :\n",
        "        normals = studio_features[np.count_nonzero(studio_features, axis=1) > 5].T\n",
        "        outliers = np.sum(studio_features[np.count_nonzero(studio_features, axis=1) <= 5].T, axis = 1)\n",
        "        out = np.zeros((normals.shape[0], normals.shape[1] + 1))\n",
        "        out[:, :-1] = normals\n",
        "        out[:, -1] = outliers\n",
        "        dim = out.shape[1]\n",
        "    \n",
        "    df[[\"studio_PC_{}\".format(i) for i in range(dim)]] = out\n",
        "    return df\n",
        "\n",
        "# Ya plein de warnings quand dim trop grand ou pas de PCA /: \n",
        "# jsp comment regler ça... en utilisant pd.concat ça tourne vraiment extrêmement lentement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "mqsGYb9ApUhz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"genres\" feature\n",
        "\"\"\"\n",
        "\n",
        "def get_genre_feature(df):\n",
        "\n",
        "    X.loc[X[\"genres\"] == \"\\\\N\", \"genres\"] = \"Others\"\n",
        "    all_genres = X[\"genres\"].copy()\n",
        "    diff_genres = []\n",
        "\n",
        "    for genres in np.unique(all_genres):\n",
        "        for genre in genres.split(\",\") :\n",
        "            if not genre in diff_genres :\n",
        "                diff_genres.append(genre)\n",
        "\n",
        "    for genre in diff_genres:\n",
        "        df[genre] = [1 if genre in genres.split(\",\") else 0 for genres in all_genres]  \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "4APQi5pKpUhz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"text_embeddings\" feature\n",
        "\"\"\"\n",
        "def get_text_embedding_feature(df, params):\n",
        "    \n",
        "    output_dim = params[\"text_embedding_PCA_dim\"] # output dimension of PCA\n",
        "\n",
        "    # Removing previously computed categorie(s) for the \"text_embedding\" initial feature\n",
        "    for feature in df.columns:\n",
        "        if len(feature) >= 18 and feature[:18] == \"text_embedding_PC_\":\n",
        "            df.drop(feature, axis=1, inplace=True)\n",
        "\n",
        "    # Creating new categorie(s) for the \"text_embedding\" initial feature\n",
        "    text_embeddings = X[\"text_embeddings\"]\n",
        "    input_dim = 768\n",
        "    embeddings = np.zeros((n_samples, input_dim))\n",
        "    for i, text_embedding in enumerate(text_embeddings):\n",
        "        embeddings[i] = list(map(float,text_embedding[1:-1].split(\",\")))\n",
        "\n",
        "    # applying PCA\n",
        "    pca = PCA(n_components=output_dim)\n",
        "    output = pca.fit_transform(embeddings)\n",
        "\n",
        "    df[[\"text_embedding_PC_{}\".format(i) for i in range(output_dim)]] = output\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Lrg6Ft1zpUh0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dealing with the \"img_embeddings\" feature\n",
        "\"\"\"\n",
        "def get_img_embedding_feature(df, params):\n",
        "    output_dim = params[\"img_embedding_PCA_dim\"] # output dimension of PCA\n",
        "\n",
        "    # Removing previously computed categorie(s) for the \"img_embedding\" initial feature\n",
        "    for feature in df.columns:\n",
        "        if len(feature) >= 17 and feature[:17] == \"img_embedding_PC_\":\n",
        "            df.drop(feature, axis=1, inplace=True)\n",
        "\n",
        "    # Creating new categorie(s) for the \"img_embedding\" initial feature\n",
        "    img_embeddings = X[\"img_embeddings\"]\n",
        "    input_dim = 2048\n",
        "    embeddings = np.zeros((n_samples, input_dim))\n",
        "    for i, img_embedding in enumerate(img_embeddings):\n",
        "        embeddings[i] = list(map(float,img_embedding[1:-1].split(\",\")))\n",
        "\n",
        "    # applying PCA\n",
        "    pca = PCA(n_components=output_dim)\n",
        "    output = pca.fit_transform(embeddings)\n",
        "\n",
        "    df[[\"img_embedding_PC_{}\".format(i) for i in range(output_dim)]] = output\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eyX6nYXvk6b"
      },
      "source": [
        "## complete preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "a0DOzTyBpUh0"
      },
      "outputs": [],
      "source": [
        "def create_preprocessed(params):\n",
        "    df = pd.DataFrame()\n",
        "    df = get_genre_feature(df)\n",
        "    df = get_directrly_usable_features(df)\n",
        "    df = get_prod_year_feature(df, params)\n",
        "    df = get_studio_feature(df, params)\n",
        "    df = get_runtime_feature(df, params)\n",
        "    df = get_text_embedding_feature(df, params)\n",
        "    df = get_img_embedding_feature(df, params)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "bzhpiUa1pUh1"
      },
      "outputs": [],
      "source": [
        "def create_preprocessed_dict(params):\n",
        "    final = {}\n",
        "    year_dict = {}\n",
        "    for val1 in params[\"production_year_style\"] :\n",
        "        for val2 in params[\"n_year_period\"] :\n",
        "            tmp = {}\n",
        "            tmp[\"production_year_style\"] = val1\n",
        "            tmp[\"n_year_period\"] = val2\n",
        "            year_dict[val1+str(val2)] = get_prod_year_feature(pd.DataFrame(), tmp)\n",
        "    final[\"year\"] = year_dict\n",
        "    \n",
        "    studio_dict = {}\n",
        "    for val1 in params[\"studio_use_PCA\"] :\n",
        "        for val2 in params[\"studio_PCA_dim\"] :\n",
        "            tmp = {}\n",
        "            tmp[\"studio_use_PCA\"] = val1\n",
        "            tmp[\"studio_PCA_dim\"] = val2\n",
        "            studio_dict[str(val1)+str(val2)] = get_studio_feature(pd.DataFrame(), tmp)\n",
        "    final[\"studio\"] = studio_dict\n",
        "    \n",
        "    runtime_dict = {}\n",
        "    for val in params[\"runtime_replace_type\"] :\n",
        "        tmp = {}\n",
        "        tmp[\"runtime_replace_type\"] = val\n",
        "        runtime_dict[val] = get_runtime_feature(pd.DataFrame(), tmp)\n",
        "    final[\"runtime\"] = runtime_dict\n",
        "    \n",
        "    text_dict = {}\n",
        "    for val in params[\"text_embedding_PCA_dim\"] :\n",
        "        tmp = {}\n",
        "        tmp[\"text_embedding_PCA_dim\"] = val\n",
        "        text_dict[val] = get_text_embedding_feature(pd.DataFrame(), tmp)\n",
        "    final[\"text\"] = text_dict\n",
        "    \n",
        "    img_dict = {}\n",
        "    for val in params[\"img_embedding_PCA_dim\"] :\n",
        "        tmp = {}\n",
        "        tmp[\"img_embedding_PCA_dim\"] = val\n",
        "        img_dict[val] = get_img_embedding_feature(pd.DataFrame(), tmp)\n",
        "    final[\"img\"] = img_dict   \n",
        "    final[\"genre\"] = get_genre_feature(pd.DataFrame())\n",
        "    final[\"base\"] = get_directrly_usable_features(pd.DataFrame())\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kUl_tHK0pUh1"
      },
      "outputs": [],
      "source": [
        "def create_preprocessed_from_dict(params_dict, params):\n",
        "    frames = []\n",
        "    frames.append(params_dict[\"genre\"])\n",
        "    frames.append(params_dict[\"base\"])\n",
        "    frames.append(params_dict[\"year\"][params[\"production_year_style\"] + str(params[\"n_year_period\"])])\n",
        "    frames.append(params_dict[\"studio\"][str(params[\"studio_use_PCA\"]) + str(params[\"studio_PCA_dim\"])])\n",
        "    frames.append(params_dict[\"runtime\"][params[\"runtime_replace_type\"]])\n",
        "    frames.append(params_dict[\"text\"][params[\"text_embedding_PCA_dim\"]])\n",
        "    frames.append(params_dict[\"img\"][params[\"img_embedding_PCA_dim\"]])\n",
        "    return pd.concat(frames, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzu12HJOpUh2"
      },
      "source": [
        "## Examples of preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "L6CQd5jzpUh2"
      },
      "outputs": [],
      "source": [
        "# Using single preprocessing\n",
        "\n",
        "params = {\n",
        "    \"production_year_style\" : \"per_quantile\", # \"per_quantile\" / \"per_period_length\" / \"no_period\"\n",
        "    \"n_year_period\" : 5,\n",
        "    \"runtime_replace_type\" : \"mean\", # \"mean\" / \"zero\" / \"median\"\n",
        "    \"studio_use_PCA\" : True,\n",
        "    \"studio_PCA_dim\" : 50,\n",
        "    \"text_embedding_PCA_dim\" : 50,\n",
        "    \"img_embedding_PCA_dim\" : 50\n",
        "}\n",
        "\n",
        "preprocessed_data = create_preprocessed(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "uAyDWmdupUh3",
        "outputId": "1f953e1a-c506-4f21-e125-6fc23b3af7bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nall_params = {\\n    \"production_year_style\" : [\"per_quantile\", \"per_period_length\", \"no_period\"], # \"per_quantile\" / \"per_period_length\" / \"no_period\"\\n    \"n_year_period\" : [3, 5, 10],\\n    \"runtime_replace_type\" : [\"mean\", \"zero\"], # \"mean\" / \"zero\" / \"median\"\\n    \"studio_use_PCA\" : [True],\\n    \"studio_PCA_dim\" : [1, 10],\\n    \"text_embedding_PCA_dim\" : [1, 10],\\n    \"img_embedding_PCA_dim\" : [1, 10]\\n}\\n\\nparams = {\\n    \"production_year_style\" : \"per_quantile\", # \"per_quantile\" / \"per_period_length\" / \"no_period\"\\n    \"n_year_period\" : 5,\\n    \"runtime_replace_type\" : \"mean\", # \"mean\" / \"zero\"\\n    \"studio_use_PCA\" : True,\\n    \"studio_PCA_dim\" : 1,\\n    \"text_embedding_PCA_dim\" : 10,\\n    \"img_embedding_PCA_dim\" : 10\\n}\\n\\npreprocessed_dict = create_preprocessed_dict(all_params)\\npreprocessed_data = create_preprocessed_from_dict(preprocessed_dict, params)\\npreprocessed_data_2 = create_preprocessed(params)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Using preprocessed dictionnary -> usefull to not compute the whole preprocessing at each iteration of the localsearch later\n",
        "\n",
        "\"\"\"\n",
        "all_params = {\n",
        "    \"production_year_style\" : [\"per_quantile\", \"per_period_length\", \"no_period\"], # \"per_quantile\" / \"per_period_length\" / \"no_period\"\n",
        "    \"n_year_period\" : [3, 5, 10],\n",
        "    \"runtime_replace_type\" : [\"mean\", \"zero\"], # \"mean\" / \"zero\" / \"median\"\n",
        "    \"studio_use_PCA\" : [True],\n",
        "    \"studio_PCA_dim\" : [1, 10],\n",
        "    \"text_embedding_PCA_dim\" : [1, 10],\n",
        "    \"img_embedding_PCA_dim\" : [1, 10]\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"production_year_style\" : \"per_quantile\", # \"per_quantile\" / \"per_period_length\" / \"no_period\"\n",
        "    \"n_year_period\" : 5,\n",
        "    \"runtime_replace_type\" : \"mean\", # \"mean\" / \"zero\"\n",
        "    \"studio_use_PCA\" : True,\n",
        "    \"studio_PCA_dim\" : 1,\n",
        "    \"text_embedding_PCA_dim\" : 10,\n",
        "    \"img_embedding_PCA_dim\" : 10\n",
        "}\n",
        "\n",
        "preprocessed_dict = create_preprocessed_dict(all_params)\n",
        "preprocessed_data = create_preprocessed_from_dict(preprocessed_dict, params)\n",
        "preprocessed_data_2 = create_preprocessed(params)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "OoIB-BycpUh4"
      },
      "outputs": [],
      "source": [
        "# preprocessed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "vZeeGjnQpUh4"
      },
      "outputs": [],
      "source": [
        "# preprocessed_data_2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvaQgGkDpUh5"
      },
      "source": [
        "# Defining our loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "XJBIIkxRpUh5"
      },
      "outputs": [],
      "source": [
        "# Score computation : Root Mean Square Error\n",
        "\n",
        "def compute_rmse(predict, target):\n",
        "    return -mean_squared_error(predict, target, squared=False)\n",
        "\n",
        "def compute_rmse2(predict, target):\n",
        "    if len(target.shape) == 2:\n",
        "        target = target.squeeze()\n",
        "    if len(predict.shape) == 2:\n",
        "        predict = predict.squeeze()\n",
        "    diff = target - predict\n",
        "    if len(diff.shape) == 1:\n",
        "        diff = np.expand_dims(diff, axis=-1)\n",
        "    rmse = np.sqrt(diff.T@diff / diff.shape[0])\n",
        "    return -float(rmse)\n",
        "\n",
        "custom_scorer = make_scorer(compute_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmVfJDSIpUh6"
      },
      "source": [
        "# Optimizing the model parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh-fHvJ1vk6d"
      },
      "source": [
        "## Our homemade mixed localsearch + randomizedsearch algorithm for the preprocessing parameters\n",
        "\n",
        "The method we used to try getting the best regressor is to use a Localsearch algorithm parsing among the above defined preprocessing parameters. For each possible preprocessing, the algorithm performs a RandomizedSearch 5-fold cross validation to select the best parameters of the given regressor. The possible values for each preprocessing and regressor parameter has to be given as imput to the algorithm.\n",
        "\n",
        "NB : You might want to reduce the thresholds for $\\texttt{no_reduce}$ in the $\\texttt{compute}$ function if performing the gridsearch on a time consuming regressor to fit such as a MLP for example (by choosing a small value of $\\texttt{max_no_upgrade}$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "6kRdsahtpUh7"
      },
      "outputs": [],
      "source": [
        "class Solution:\n",
        "    def __init__(self, params, grid_params, score, RSCV):\n",
        "        self.grid_params = grid_params\n",
        "        self.params = params\n",
        "        self.score = score\n",
        "        self.RSCV = RSCV\n",
        "\n",
        "class LocalSearch :\n",
        "    \n",
        "    def __init__(self, regressor, params, grid_params, max_no_upgrade):\n",
        "        self.curr_score = []\n",
        "        self.best_score = []\n",
        "        self.regressor = regressor\n",
        "        self.params = params\n",
        "        self.preprocessed_dict = create_preprocessed_dict(params)\n",
        "        self.grid_params = grid_params\n",
        "        self.visited = []\n",
        "        self.max_no_upgrade = max_no_upgrade\n",
        "\n",
        "    \n",
        "    def clean(self, params):\n",
        "        copied = copy.deepcopy(params)\n",
        "        if copied[\"production_year_style\"] == \"no_period\":\n",
        "            copied.pop(\"n_year_period\")\n",
        "        if copied[\"studio_use_PCA\"] == False:\n",
        "            copied.pop(\"studio_PCA_dim\")\n",
        "        return copied\n",
        "    \n",
        "    def is_visited(self, params):\n",
        "        return str(self.clean(params)) in self.visited\n",
        "    \n",
        "    def visit(self, params):\n",
        "        self.visited.append(str(self.clean(params)))\n",
        "    \n",
        "    def get_solution(self, params):\n",
        "        preprocessed_data = copy.deepcopy(create_preprocessed_from_dict(self.preprocessed_dict, params))\n",
        "        RSCV = RandomizedSearchCV(regressor, self.grid_params, cv=5, scoring=custom_scorer, n_jobs=-1, random_state=0)\n",
        "        RSCV.fit(preprocessed_data, Y1)\n",
        "        current_score = np.mean(RSCV.best_score_)\n",
        "        self.visit(params)\n",
        "        return Solution(params, RSCV.best_params_, current_score, RSCV)\n",
        "    \n",
        "    def initiate(self):\n",
        "        current_params = {}\n",
        "        for param in self.params.keys():\n",
        "            current_params[param] = np.random.choice(self.params[param])\n",
        "        self.current_solution = self.get_solution(current_params)\n",
        "        self.best_solution = copy.deepcopy(self.current_solution)\n",
        "    \n",
        "    def transitions(self):\n",
        "        neighbors = []\n",
        "        current_params = self.current_solution.params\n",
        "        for param in self.params.keys():\n",
        "            copied = copy.deepcopy(self.params[param])\n",
        "            np.random.shuffle(copied)\n",
        "            for value in copied:\n",
        "                new_params = copy.deepcopy(current_params)\n",
        "                new_params[param] = value\n",
        "                if not self.is_visited(new_params):\n",
        "                    neighbors.append(new_params)\n",
        "                    break\n",
        "        return neighbors\n",
        "    \n",
        "    def choose(self, neighbors, n):\n",
        "        if len(neighbors) <= n :\n",
        "            return neighbors\n",
        "        return np.random.choice(neighbors, size=n, replace = False)\n",
        "    \n",
        "    def get_difference(self, other):\n",
        "        first = self.current_solution.params\n",
        "        for param in first.keys():\n",
        "            if first[param] != other[param]:\n",
        "                return param, first[param], other[param]\n",
        "        return None\n",
        "    \n",
        "    def compute(self):\n",
        "        self.initiate()\n",
        "        print(\"INITIALISATION ENDED : initial score of {:.2e} $\".format(self.best_solution.score))\n",
        "        no_upgrade = 0;\n",
        "        while no_upgrade <= self.max_no_upgrade:\n",
        "            neighbors = self.transitions()\n",
        "            if len(neighbors) == 0:\n",
        "                break\n",
        "            neighbors = self.choose(neighbors, 5)\n",
        "            curr_best_sol = Solution(None, None, -float(\"inf\"), None)\n",
        "            for neighbor in neighbors :\n",
        "                solution = self.get_solution(neighbor)\n",
        "                if solution.score > curr_best_sol.score :\n",
        "                    curr_best_sol = solution\n",
        "                diff = self.get_difference(neighbor)\n",
        "                # print(\"{} : {} -> {} score {:.2%}\".format(diff[0], diff[1], diff[2],solution.score))\n",
        "            self.current_solution = copy.deepcopy(curr_best_sol)\n",
        "            # print(\"updated current\")\n",
        "            if curr_best_sol.score > self.best_solution.score:\n",
        "                self.best_solution = copy.deepcopy(curr_best_sol)\n",
        "                print(\"SOLUTION UPGRADED : new score of {:.2e} $\".format(self.best_solution.score))\n",
        "                no_upgrade = 0\n",
        "\n",
        "            self.curr_score.append(self.current_solution.score)\n",
        "            self.best_score.append(self.best_solution.score)\n",
        "            no_upgrade += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXrHyJaavk6e"
      },
      "source": [
        "## Some nice printing and plotting functions for the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "LAiX7c8Lvk6e"
      },
      "outputs": [],
      "source": [
        "def print_solution(regressor, solution):\n",
        "    print(f\"The {regressor} Regressor reaches mean RMSE of {-solution.score:.4e} $.\")\n",
        "    var = solution.RSCV.cv_results_['std_test_score'][solution.RSCV.best_index_]\n",
        "    print(f\"This RMSE has a variance of {var:.4e}\")\n",
        "    data = [[\"PARAMETER\", \"VALUE\"]] + [[key, solution.params[key]] for key in solution.params.keys()]\n",
        "    col_widths = [max(len(str(row[i])) for row in data) for i in range(len(data[0]))]\n",
        "    print(\"\\nPreprocessing :\")\n",
        "    for row in data:\n",
        "        print(' '.join(str(cell).ljust(col_widths[i]) for i, cell in enumerate(row)))\n",
        "\n",
        "    data = [[\"PARAMETER\", \"VALUE\"]] + [[key, solution.grid_params[key]] for key in solution.grid_params.keys()]\n",
        "    col_widths = [max(len(str(row[i])) for row in data) for i in range(len(data[0]))]\n",
        "    print(\"\\nRegressor :\")\n",
        "    for row in data:\n",
        "        print(' '.join(str(cell).ljust(col_widths[i]) for i, cell in enumerate(row)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "CjYtdjIYvk6e"
      },
      "outputs": [],
      "source": [
        "def print_evolution(LS, name):\n",
        "    current_scores = np.array(LS.curr_score)\n",
        "    best_scores = np.array(LS.best_score)\n",
        "    iter = np.arange(1, len(current_scores)+1)\n",
        "    plt.plot(iter, -current_scores, label=\"current solution\", color=\"blue\", linestyle=\"--\")\n",
        "    plt.plot(iter, -best_scores, label=\"best solution\", color=\"red\")\n",
        "    plt.title(\"Local search score evolution\", fontsize=20)\n",
        "    plt.ylabel(\"avg RMSE on 5-fold\")\n",
        "    plt.xlabel(\"iter\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(f\"LS{name}.png\")\n",
        "    plt.show()\n",
        "\n",
        "def print_last_RSCV_evolution(solution, name):\n",
        "    RSCV = solution.RSCV\n",
        "    RMSE = RSCV.cv_results_['mean_test_score']\n",
        "    # Plot the scores as a function of the iteration\n",
        "    plt.plot(range(1, len(RMSE)+1), -RMSE)\n",
        "    plt.xlabel('iter')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title(\"Randomized search score evolution\")\n",
        "    plt.grid()\n",
        "    plt.savefig(f\"RSCV{name}.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR4NDqm8vk6e"
      },
      "source": [
        "## Choosing our preprocessing parameters possibilities for the optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ZSPAymS2vk6e"
      },
      "outputs": [],
      "source": [
        "preprocessing_params = {\n",
        "    \"production_year_style\" : [\"per_quantile\", \"per_period_length\", \"no_period\"], # \"per_quantile\" / \"per_period_length\" / \"no_period\"\n",
        "    \"n_year_period\" : [3, 5, 10],\n",
        "    \"runtime_replace_type\" : [\"mean\", \"zero\", \"median\"], # \"mean\" / \"zero\" / \"median\"\n",
        "    \"studio_use_PCA\" : [False],\n",
        "    \"studio_PCA_dim\" : [10], # this parameter has no use since we finally do not use PCA on the studio feature\n",
        "    \"text_embedding_PCA_dim\" : [1, 10, 20, 50, 100],\n",
        "    \"img_embedding_PCA_dim\" : [1, 10, 20, 50, 100]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiJSyFvgvk6e"
      },
      "source": [
        "## Optimizing an OLS Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLvLImyvvk6e",
        "outputId": "ace60ceb-aa9f-4b6a-ddae-056cb9645754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INITIALISATION ENDED : initial score of -5.76e+07 $\n",
            "SOLUTION UPGRADED : new score of -5.67e+07 $\n"
          ]
        }
      ],
      "source": [
        "regressor_params = {\n",
        "    \"fit_intercept\": [False] # Set any parameter for the RandomizedSearch to work even if no preprocessing parameter is important.\n",
        "}\n",
        "\n",
        "max_no_upgrade = 20\n",
        "regressor = LinearRegression()\n",
        "LSOLS = LocalSearch(regressor, preprocessing_params, regressor_params, max_no_upgrade)\n",
        "LSOLS.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2aHncbbvk6f"
      },
      "outputs": [],
      "source": [
        "solution = LSOLS.best_solution\n",
        "print_solution(\"OLS\", solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkZaHkrSvk6f"
      },
      "outputs": [],
      "source": [
        "print_evolution(LSOLS, \"OLS\")\n",
        "# print_last_RSCV_evolution(solution, \"OLS\") # this plot is useless since no parameter optimisation has to be done for OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTGQ5Gbevk6f"
      },
      "source": [
        "## Optimizing a Ridge Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOcNeDAJvk6f"
      },
      "outputs": [],
      "source": [
        "regressor_params = {\n",
        "    \"alpha\": [1e-1, 5e-1, 1, 5, 10, 20]\n",
        "}\n",
        "\n",
        "regressor = Ridge()\n",
        "max_no_upgrade = 20\n",
        "LSRidge = LocalSearch(regressor, preprocessing_params, regressor_params, max_no_upgrade)\n",
        "LSRidge.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsShyRnFpUh7"
      },
      "outputs": [],
      "source": [
        "solution = LSRidge.best_solution\n",
        "print(solution.RSCV.best_score_)\n",
        "print_solution(\"Ridge\", solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28xo0tX_c9ob"
      },
      "outputs": [],
      "source": [
        "print_evolution(LSRidge, \"Ridge\")\n",
        "print_last_RSCV_evolution(solution, \"Ridge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR_-tyXRpUh8"
      },
      "source": [
        "## Optimizing a KNN regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Dmenduvk6g"
      },
      "outputs": [],
      "source": [
        "regressor_params = {\n",
        "    'n_neighbors' : [2, 5, 10, 20, 50], \n",
        "    'weights' : ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "max_no_upgrade = 20\n",
        "regressor = KNeighborsRegressor()\n",
        "LSKNN = LocalSearch(regressor, preprocessing_params, regressor_params, max_no_upgrade)\n",
        "LSKNN.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qmNMyQQvk6g"
      },
      "outputs": [],
      "source": [
        "solution = LSKNN.best_solution\n",
        "print_solution(\"KNN\", solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btVJ0n_Pvk6h"
      },
      "outputs": [],
      "source": [
        "print_evolution(LSKNN)\n",
        "print_last_RSCV_evolution(solution, \"KNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmi0SQeRpUh9"
      },
      "source": [
        "## Optimizing a MLP regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccg4W3C8pUh9"
      },
      "outputs": [],
      "source": [
        "regressor_params =    {\n",
        "    'hidden_layer_sizes' : [(50,50), (100,)],\n",
        "    'activation' : ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [500]\n",
        "}\n",
        "\n",
        "max_no_upgrade = 10\n",
        "regressor = MLPRegressor(random_state=0)\n",
        "LSMLP = LocalSearch(regressor, preprocessing_params, regressor_params, max_no_upgrade)\n",
        "LSMLP.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqQeDAqWvk6h"
      },
      "outputs": [],
      "source": [
        "solution = LSMLP.best_solution\n",
        "print_solution(\"MLP\", solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf3zBlSnvk6h"
      },
      "outputs": [],
      "source": [
        "print_evolution(LSMLP, \"MLP\")\n",
        "print_last_RSCV_evolution(solution, \"MLP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbhKad95vk6h"
      },
      "source": [
        "## Optimizing a Random Forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOsmpf0gvk6h"
      },
      "outputs": [],
      "source": [
        "regressor_params = {\n",
        "    \"n_estimators\": [50, 100, 200], \n",
        "    \"criterion\": [\"squared_error\"], # [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
        "    \"min_samples_split\": [1.0, 3],     # [1, 2, 3],\n",
        "    \"max_features\" : [\"sqrt\", \"log2\"],      # [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "max_no_upgrade = 10\n",
        "regressor = RandomForestRegressor(n_jobs=-1,random_state=0)\n",
        "LSRF = LocalSearch(regressor, preprocessing_params, regressor_params, max_no_upgrade)\n",
        "LSRF.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYwkPp3pvk6i"
      },
      "outputs": [],
      "source": [
        "solution = LSRF.best_solution\n",
        "print_solution(\"Random Forest\", solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBiDN4Ijvk6i"
      },
      "outputs": [],
      "source": [
        "print_evolution(LSRF, \"RF\")\n",
        "print_last_RSCV_evolution(solution, \"RF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZc6SCiUpkuT"
      },
      "source": [
        "## Our own MLP implementation with torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GF0I48Upj81"
      },
      "outputs": [],
      "source": [
        "preprocessing_params = LSOLS.best_solution.params\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(create_preprocessed(preprocessing_params), Y1, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt8bVrVRpajK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "input_size = len(X_train.columns)\n",
        "output_size = 1\n",
        "\n",
        "num_hidden_layers = 2\n",
        "hidden_layer_size = 100\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(input_size, hidden_layer_size),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(hidden_layer_size, output_size)\n",
        ").to(device)\n",
        "model = model.double()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "lr = 1e-3\n",
        "betas = (0.9, 0.999)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "inputs = X_train.to_numpy()\n",
        "targets = y_train.to_numpy()\n",
        "inputs = torch.from_numpy(inputs).to(device).double()\n",
        "targets = torch.from_numpy(targets).to(device).double()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = []\n",
        "    for i in range(0, len(inputs)):\n",
        "        batch_inputs = inputs[i]\n",
        "        batch_targets = targets[i]\n",
        "        outputs = model.forward(batch_inputs)\n",
        "        loss = loss_fn(outputs, batch_targets)\n",
        "        train_loss.append(loss)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the average train loss for the current epoch\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {torch.sqrt(sum(train_loss)/len(train_loss))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge9lZzygvmMh"
      },
      "outputs": [],
      "source": [
        "inputs_test = X_test.to_numpy()\n",
        "inputs_test = torch.from_numpy(inputs_test).to(device).double()\n",
        "targets_test = y_test.to_numpy()\n",
        "targets_test = torch.from_numpy(targets_test).to(device).double()\n",
        "\n",
        "outputs_test = model.forward(inputs_test)\n",
        "outputs_test = outputs_test.cpu().detach().numpy()\n",
        "print(\"{:.2e} is the final error\".format(compute_rmse(outputs_test, y_test)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "9abed8abd2ce500fe15b078df5e406127fe6c9e241ddd0cff9b21749bf3b9f14"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}